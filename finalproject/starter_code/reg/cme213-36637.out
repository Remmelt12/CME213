The master node of this job is gpu-202-3
This job runs on the following nodes:
gpu-202-3
Starting at Sun Jun 10 20:47:45 PDT 2018
Running on hosts: gpu-202-3
Running on 1 nodes.
Running on 24 processors.
Current working directory is ./

Output from code
----------------
Number of MPI processes = 4
Number of CUDA devices = 4
num_neuron=1000, reg=1e-05, learning_rate=0.001, num_epochs=20, batch_size=800
Loading training data...
Training data stats...
Size of x_train, N =  60000
Size of label_train = 60000
Start Sequential Training
Time for Sequential Training: 509.025 seconds
Precision on validation set for sequential training = 0.909833

Start Parallel Training
Time for Parallel Training: 46.8648 seconds
Precision on validation set for parallel training = 0.909833
